{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xtreme (/Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ef55e6a3a24fe0802004736e98720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load only PAN-X.de subset\n",
    "from datasets import load_dataset\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xtreme (/Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c953462473d14d1ab8b328566f40c528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-7318edec81f76aa6.arrow\n",
      "Parameter 'indices'=range(0, 6290) of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-cbd29dccd93ef58f.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4433310f7a3b2793.arrow\n",
      "Reusing dataset xtreme (/Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd0ca58936947568bfc82888d5e1b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4a1996403248b4e2.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-5d4f9e5aefa05972.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-6789784a489dc7d6.arrow\n",
      "Reusing dataset xtreme (/Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c301136aa4341418d7bf172c938648c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-845df155c04c1192.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-4038e5f0ccb7a363.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-e220bc62f3b2de61.arrow\n",
      "Reusing dataset xtreme (/Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98f945029584d7fbcc7fdf3a0072b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-2292d48c0b6f8502.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-56d73ebf7717cb83.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/shamweelmohammed/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-5117c26f1eb0d215.arrow\n"
     ]
    }
   ],
   "source": [
    "# To make a realistic Swiss corpus, we’ll sample the German (de), French (fr), Italian\n",
    "# (it), and English (en) corpora from PAN-X according to their spoken proportions.\n",
    "\n",
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "        ds[split]\n",
    "        .shuffle(seed=0)\n",
    "        .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678c336ae57243e9b60aff1a7e117281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6290 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648476080bb7403480fe8ddacb2f1b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6290 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b87bceee674a9b82c2915ba61581c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12580 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8    \n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen  \\\n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The presence of the LOC tags make sense since the sentence “2,000 Einwohnern an der\n",
    "# Danziger Bucht in der polnischen Woiwodschaft Pommern” means “2,000 inhabitants\n",
    "# at the Gdansk Bay in the Polish voivodeship of Pomerania” in English, and\n",
    "# Gdansk Bay is a bay in the Baltic sea, while “voivodeship” corresponds to a state in\n",
    "# Poland.\n",
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>2683</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2573</td>\n",
       "      <td>3180</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5366</td>\n",
       "      <td>6186</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   LOC   PER\n",
       "validation  2683  3172  2893\n",
       "test        2573  3180  3071\n",
       "train       5366  6186  5810"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the frequencies of each entity across each split\n",
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual transformer models are usually evaluated in three different ways:\n",
    "# en\n",
    "# Fine-tune on the English training data and then evaluate on each language’s test\n",
    "# set.\n",
    "# each\n",
    "# Fine-tune and evaluate on monolingual test data to measure per-language\n",
    "# performance.\n",
    "# all\n",
    "# Fine-tune on all the training data to evaluate on all on each language’s test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n",
      "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "print(bert_tokens)\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
    "print(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Token Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask, token_type_ids, **kwargs)\n",
    "        # Use 1st output (from last layer) as encoder representations\n",
    "        sequence_output = outputs[0]\n",
    "        # Apply dropout for regularization\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        # Return TokenClassifierOutput\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "print(index2tag)\n",
    "print(tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlm_config = AutoConfig.from_pretrained(xlmr_model_name, num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "xlmr_model = XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlm_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n",
      "Outputs: tensor([[[ 0.2922,  0.6862, -0.7389,  0.0636, -0.2006, -0.1279,  0.1889],\n",
      "         [ 0.2431,  0.3937, -0.4349,  0.3774, -0.3441, -0.1218,  0.3197],\n",
      "         [ 0.0841,  0.4032, -0.5379,  0.3731, -0.2642, -0.3202,  0.1941],\n",
      "         [ 0.1429,  0.3501, -0.4901,  0.3608, -0.3330, -0.2014,  0.3510],\n",
      "         [ 0.2431,  0.4884, -0.3635,  0.4455, -0.3316, -0.0929,  0.2971],\n",
      "         [ 0.1838,  0.4615, -0.4126,  0.3604, -0.3851, -0.1456,  0.3559],\n",
      "         [ 0.2213,  0.4656, -0.4336,  0.3911, -0.3065, -0.1020,  0.3315],\n",
      "         [ 0.3019,  0.4491, -0.3926,  0.3940, -0.3103, -0.1015,  0.3851],\n",
      "         [ 0.2029,  0.5264, -0.4473,  0.3974, -0.3373, -0.1781,  0.2936],\n",
      "         [ 0.3472,  0.5900, -0.7768,  0.1258, -0.2185, -0.1049,  0.1419]]],\n",
      "       device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Predictions: tensor([[1, 1, 1, 3, 1, 1, 1, 1, 1, 1]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\") # (batch_size, sequence_length, num_tags)\n",
    "print(f\"Outputs: {outputs}\")\n",
    "\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    B-PER  B-PER  B-PER  B-ORG  B-PER  B-PER  B-PER  B-PER  B-PER  B-PER"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get the model outputs\n",
    "    model = model.to(device)\n",
    "    outputs = model(input_ids).logits\n",
    "    predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "    # Get the predicted tags\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8    \n",
       "words   2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen  \\\n",
       "labels      0           0   0    0         5      6   0    0           5   \n",
       "\n",
       "                  9        10 11  \n",
       "words   Woiwodschaft  Pommern  .  \n",
       "labels             5        6  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the XLM-R tokenizer returns the input IDs for the model’s inputs, we just need\n",
    "# to augment this information with the attention mask and the label IDs that encode\n",
    "# the information about which token is associated with each NER tag.\n",
    "\n",
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n",
    "pd.DataFrame([words, labels], index=[\"words\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15   \n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo  \\\n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...   \n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  \\\n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    # Special tokens have a word id that is None. We set the label to -100 so they are automatically \n",
    "    # ignored in the loss function.\n",
    "    if word_idx is None:\n",
    "        label_ids.append(-100)\n",
    "\n",
    "    # We set the label for the first token of each word.\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    # For the other tokens in a word, we set the label to either the current label or -100,\n",
    "    # depending on the label_all_tokens flag.\n",
    "    else:\n",
    "        label_ids.append(-100)\n",
    "    previous_word_idx = word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8    \n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger  \\\n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23   \n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .  \\\n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_id = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_id:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically \n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100,\n",
    "            # depending on the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True,\n",
    "            remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8945031067cb4cb1b0e1f90db69d43a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db32cb3f3d94824b3e81528f90e0aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c40419479b4fdb946d7e8b4b6f07a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_de_encoded = encode_dataset(panx_ch[\"de\"])\n",
    "# panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len :  3\n"
     ]
    }
   ],
   "source": [
    "print(f\"len : \",len(panx_de_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "[\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "[\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    batch_size, seq_len = preds.shape\n",
    "\n",
    "    labels_list, preds_list = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically \n",
    "            # ignored in the loss function.\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx, seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx, seq_idx]])\n",
    "    \n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "# We use F1 score as evaluation metric\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
    "    return {\n",
    "        \"f1\": f1_score(y_true, y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09371096a15b4c4bbbc53f85c1d0cc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging every 524 steps.\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune base model on the German subset of PAN-X and then evaluate its zeroshot\n",
    "# cross-lingual performance on French, Italian, and English\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "print(f\"Logging every {logging_steps} steps.\")\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "        .from_pretrained(xlmr_model_name, config=xlm_config)\n",
    "        .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                    train_dataset=panx_de_encoded[\"train\"],\n",
    "                    eval_dataset=panx_de_encoded[\"validation\"],\n",
    "                    tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc17e3647d6474b85bde715de7433e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2531, 'learning_rate': 3.3365079365079365e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349074da8f9144c8a0ae93798887ba88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.179510697722435, 'eval_f1': 0.8092165898617512, 'eval_runtime': 131.7357, 'eval_samples_per_second': 47.747, 'eval_steps_per_second': 1.996, 'epoch': 1.0}\n",
      "{'loss': 0.1289, 'learning_rate': 1.673015873015873e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c780bd9714f4972b502a75d8a88d7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1359851211309433, 'eval_f1': 0.8490295986717811, 'eval_runtime': 487.6015, 'eval_samples_per_second': 12.9, 'eval_steps_per_second': 0.539, 'epoch': 2.0}\n",
      "{'loss': 0.0819, 'learning_rate': 9.523809523809524e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a015e7188642e1b56102b86dd025f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13745883107185364, 'eval_f1': 0.8615332274892267, 'eval_runtime': 134.9174, 'eval_samples_per_second': 46.621, 'eval_steps_per_second': 1.949, 'epoch': 3.0}\n",
      "{'train_runtime': 4734.6438, 'train_samples_per_second': 7.971, 'train_steps_per_second': 0.333, 'train_loss': 0.1544913813802931, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1575, training_loss=0.1544913813802931, metrics={'train_runtime': 4734.6438, 'train_samples_per_second': 7.971, 'train_steps_per_second': 0.333, 'train_loss': 0.1544913813802931, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4     5           6    7     8        9    \n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google  \\\n",
       "Tags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'torch._C.Generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# with open(f\"{model_name}/trainer.dill\", \"wb\") as f:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#     dill.dump(trainer, f)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m# import pickle\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/trainer.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 8\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(trainer, f) \n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:235\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[1;32m    233\u001b[0m _kwds \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    234\u001b[0m _kwds\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(byref\u001b[39m=\u001b[39mbyref, fmode\u001b[39m=\u001b[39mfmode, recurse\u001b[39m=\u001b[39mrecurse))\n\u001b[0;32m--> 235\u001b[0m Pickler(file, protocol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwds)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:394\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(\u001b[39mself\u001b[39m, obj): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     logger\u001b[39m.\u001b[39mtrace_setup(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 394\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (3 times), _Pickler._batch_setitems at line 997 (1 times), _Pickler.save at line 603 (1 times), _Pickler.save at line 560 (1 times), _Pickler.save_dict at line 971 (1 times), save_module_dict at line 1186 (1 times), _Pickler.save_reduce at line 717 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         save(state)\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Pickler.save at line 388 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:1186\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1187\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1188\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         save(v)\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/site-packages/dill/_dill.py:388\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    386\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 388\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers-book/lib/python3.8/pickle.py:578\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    576\u001b[0m reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     rv \u001b[39m=\u001b[39m reduce(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproto)\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'torch._C.Generator' object"
     ]
    }
   ],
   "source": [
    "# Save trainer as a dill file\n",
    "import dill as pickle\n",
    "# with open(f\"{model_name}/trainer.dill\", \"wb\") as f:\n",
    "#     dill.dump(trainer, f)\n",
    "\n",
    "# import pickle\n",
    "with open(f\"{model_name}/trainer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trainer, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss per token\n",
    "\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    # Example below:\n",
    "    # {\n",
    "    #     \"attention_mask\" : [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]],\n",
    "    #     'input_ids': [[0, 10699, 11, 15, 16104, 1388, 2], [0, 56530, 25216, 30121, 15263, 2]],\n",
    "    #     'labels': [[-100, 3, -100, 4, 4, 4, -100], [-100, 0, -100, -100, -100, -100, 3]]\n",
    "    # }\n",
    "    # Example output:\n",
    "    # [\n",
    "    #     {'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 10699, 11, 15, 16104, 1388, 2], 'labels': [-100, 3, -100, 4, 4, 4, -100]},\n",
    "    #     {'attention_mask': [1, 1, 1, 1], 'input_ids': [0, 56530, 25216, 30121, 15263, 2], 'labels': [-100, 0, -100, -100, -100, -100, 3]}\n",
    "    # ]\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        logit = output.logits\n",
    "        predicted_label = torch.argmax(logit, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(logit.view(-1, 7),\n",
    "                        labels.view(-1), reduction=\"none\")\n",
    "    # print(\"loss.size():\", loss.size())\n",
    "\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    # print(\"loss:\", loss)\n",
    "    # print(\"loss.shape:\", loss.shape)\n",
    "\n",
    "    return {\n",
    "        \"loss\":loss,\n",
    "        \"predicted_label\": predicted_label\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0ef51ecaf84caca1a077a34e833383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/197 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         attention_mask   \n",
      "0                                 [1, 1, 1, 1, 1, 1, 1]  \\\n",
      "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "2            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "3                           [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "...                                                 ...   \n",
      "6285  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "6286                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "6287  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "6288               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
      "6289                              [1, 1, 1, 1, 1, 1, 1]   \n",
      "\n",
      "                                              input_ids   \n",
      "0                    [0, 10699, 11, 15, 16104, 1388, 2]  \\\n",
      "1     [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n",
      "2     [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n",
      "3        [0, 16459, 242, 5106, 6, 198715, 5106, 242, 2]   \n",
      "4     [0, 11022, 2315, 7418, 1079, 8186, 57242, 97, ...   \n",
      "...                                                 ...   \n",
      "6285  [0, 10333, 599, 7418, 4180, 72, 3700, 542, 900...   \n",
      "6286    [0, 15497, 7, 91243, 15, 23924, 96220, 1388, 2]   \n",
      "6287  [0, 1858, 566, 12241, 729, 4598, 89841, 68125,...   \n",
      "6288  [0, 132005, 11399, 7, 84974, 168, 34525, 84247...   \n",
      "6289               [0, 242, 5106, 223660, 5106, 242, 2]   \n",
      "\n",
      "                                                 labels   \n",
      "0                        [-100, 3, -100, 4, 4, 4, -100]  \\\n",
      "1     [-100, 0, -100, -100, -100, -100, 3, -100, -10...   \n",
      "2     [-100, 0, 0, 0, 0, 3, -100, -100, 0, -100, 0, ...   \n",
      "3                  [-100, 0, 0, 0, 5, -100, 0, 0, -100]   \n",
      "4     [-100, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 3, ...   \n",
      "...                                                 ...   \n",
      "6285  [-100, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, -10...   \n",
      "6286            [-100, 5, -100, -100, 6, 6, 6, 6, -100]   \n",
      "6287  [-100, 0, 0, 0, 0, -100, 0, -100, -100, 0, 0, ...   \n",
      "6288   [-100, 0, 0, -100, 0, 0, 5, 6, 0, 0, -100, -100]   \n",
      "6289                        [-100, 0, 0, 1, 0, 0, -100]   \n",
      "\n",
      "                                                   loss   \n",
      "0     [-0.0, 0.022683436, -0.0, 0.03537199, 0.020865...  \\\n",
      "1     [-0.0, 0.00016366097, -0.0, -0.0, -0.0, -0.0, ...   \n",
      "2     [-0.0, 0.00021288513, 0.000109904926, 0.000177...   \n",
      "3     [-0.0, 0.00029702543, 0.00023350373, 0.0004500...   \n",
      "4     [-0.0, 9.917721e-05, 0.00011300402, 0.00010883...   \n",
      "...                                                 ...   \n",
      "6285  [-0.0, 0.00010108437, 8.9164576e-05, 9.822363e...   \n",
      "6286  [-0.0, 0.006375332, -0.0, -0.0, 0.0050993855, ...   \n",
      "6287  [-0.0, 0.00013922676, 0.00012075172, 0.0001885...   \n",
      "6288  [-0.0, 0.0002512616, 0.004791445, -0.0, 0.0001...   \n",
      "6289  [-0.0, 0.00023290783, 0.0003100153, 3.2069006,...   \n",
      "\n",
      "                                        predicted_label  \n",
      "0     [4, 3, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1     [6, 0, 0, 0, 0, 0, 5, 6, 6, 4, 4, 4, 4, 6, 6, ...  \n",
      "2     [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3     [5, 0, 0, 0, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, ...  \n",
      "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, ...  \n",
      "...                                                 ...  \n",
      "6285  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, ...  \n",
      "6286  [6, 5, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, ...  \n",
      "6287  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6288  [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6289  [5, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "[6290 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = valid_set.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "df['input_tokens'] = df['input_ids'].apply(lambda x : xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[-0.0, 0.022683436, -0.0, 0.03537199, 0.020865...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 56530, 25216, 30121, 152385, 19229, 83982,...</td>\n",
       "      <td>[IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...</td>\n",
       "      <td>[-0.0, 0.00016366097, -0.0, -0.0, -0.0, -0.0, ...</td>\n",
       "      <td>[I-LOC, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-...</td>\n",
       "      <td>[&lt;s&gt;, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 159093, 165, 38506, 122, 153080, 29088, 57...</td>\n",
       "      <td>[IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...</td>\n",
       "      <td>[-0.0, 0.00021288513, 0.000109904926, 0.000177...</td>\n",
       "      <td>[O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      attention_mask   \n",
       "0                              [1, 1, 1, 1, 1, 1, 1]  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                           input_ids   \n",
       "0                 [0, 10699, 11, 15, 16104, 1388, 2]  \\\n",
       "1  [0, 56530, 25216, 30121, 152385, 19229, 83982,...   \n",
       "2  [0, 159093, 165, 38506, 122, 153080, 29088, 57...   \n",
       "\n",
       "                                              labels   \n",
       "0        [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]  \\\n",
       "1  [IGN, O, IGN, IGN, IGN, IGN, B-ORG, IGN, IGN, ...   \n",
       "2  [IGN, O, O, O, O, B-ORG, IGN, IGN, O, IGN, O, ...   \n",
       "\n",
       "                                                loss   \n",
       "0  [-0.0, 0.022683436, -0.0, 0.03537199, 0.020865...  \\\n",
       "1  [-0.0, 0.00016366097, -0.0, -0.0, -0.0, -0.0, ...   \n",
       "2  [-0.0, 0.00021288513, 0.000109904926, 0.000177...   \n",
       "\n",
       "                                     predicted_label   \n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]  \\\n",
       "1  [I-LOC, O, O, O, O, O, B-LOC, I-LOC, I-LOC, I-...   \n",
       "2     [O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                        input_tokens  \n",
       "0         [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  \n",
       "1  [<s>, ▁WE, ITE, RL, EIT, UNG, ▁Luz, ky, j, ▁a,...  \n",
       "2  [<s>, ▁entdeckt, ▁und, ▁gehört, ▁der, ▁Spek, t...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attention_mask input_ids labels      loss predicted_label  input_tokens\n",
      "0              1         0    IGN      -0.0           I-ORG           <s>\n",
      "0              1     10699  B-ORG  0.022683           B-ORG          ▁Ham\n",
      "0              1        11    IGN      -0.0           I-ORG             a\n",
      "0              1        15  I-ORG  0.035372           I-ORG            ▁(\n",
      "0              1     16104  I-ORG  0.020865           I-ORG  ▁Unternehmen\n",
      "0              1      1388  I-ORG  0.028126           I-ORG            ▁)\n",
      "0              1         2    IGN      -0.0           I-ORG          </s>\n",
      "1              1         0    IGN      -0.0           I-LOC           <s>\n",
      "1              1     56530      O  0.000164               O           ▁WE\n",
      "1              1     25216    IGN      -0.0               O           ITE\n"
     ]
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "print(df_tokens.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10699</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.04</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16104</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1388</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56530</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>83982</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.99</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.77</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  attention_mask input_ids labels  loss predicted_label  input_tokens\n",
       "0              1     10699  B-ORG  0.02           B-ORG          ▁Ham\n",
       "0              1        15  I-ORG  0.04           I-ORG            ▁(\n",
       "0              1     16104  I-ORG  0.02           I-ORG  ▁Unternehmen\n",
       "0              1      1388  I-ORG  0.03           I-ORG            ▁)\n",
       "1              1     56530      O  0.00               O           ▁WE\n",
       "1              1     83982  B-ORG  0.99           B-LOC          ▁Luz\n",
       "1              1        10  I-ORG  0.77           I-ORG            ▁a"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by input tokens and aggregate loss per token by count, mean and sum to find out tokens with most loss in val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>989</td>\n",
       "      <td>1388</td>\n",
       "      <td>808</td>\n",
       "      <td>1171</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>2898</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>194.79</td>\n",
       "      <td>131.06</td>\n",
       "      <td>117.25</td>\n",
       "      <td>105.57</td>\n",
       "      <td>93.46</td>\n",
       "      <td>81.8</td>\n",
       "      <td>75.68</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.54</td>\n",
       "      <td>53.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3      4     5      6     7      8   \n",
       "input_tokens       ▁     ▁in    ▁der    ▁von   ▁und    ▁/     ▁(    ▁)    ▁''  \\\n",
       "count           6066     989    1388     808   1171   163    246   246   2898   \n",
       "mean            0.03    0.13    0.08    0.13   0.08   0.5   0.31  0.28   0.02   \n",
       "sum           194.79  131.06  117.25  105.57  93.46  81.8  75.68  68.0  62.54   \n",
       "\n",
       "                  9  \n",
       "input_tokens     ▁A  \n",
       "count           125  \n",
       "mean           0.43  \n",
       "sum           53.89  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "                .agg([\"count\", \"mean\", \"sum\"])\n",
    "                .droplevel(level=0, axis=1) # Get rid of multi-level columns\n",
    "                .sort_values(by=\"sum\", ascending=False)\n",
    "                .reset_index()\n",
    "                .round(2)\n",
    "                .head(10)\n",
    "                .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by label IDs and view losses for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2683</td>\n",
       "      <td>1462</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1653.94</td>\n",
       "      <td>890.97</td>\n",
       "      <td>1821.92</td>\n",
       "      <td>1110.74</td>\n",
       "      <td>742.25</td>\n",
       "      <td>770.89</td>\n",
       "      <td>1481.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1        2        3       4       5        6\n",
       "labels    B-ORG   I-LOC    I-ORG    B-LOC   B-PER   I-PER        O\n",
       "count      2683    1462     3820     3172    2893    4139    43648\n",
       "mean       0.62    0.61     0.48     0.35    0.26    0.19     0.03\n",
       "sum     1653.94  890.97  1821.92  1110.74  742.25  770.89  1481.49"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "                .agg([\"count\", \"mean\", \"sum\"])\n",
    "                .droplevel(level=0, axis=1)\n",
    "                .sort_values(by=\"mean\", ascending=False)\n",
    "                .reset_index()\n",
    "                .round(2)\n",
    "                .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B-ORG has highest average loss, which means that determining the beginning of an organization is a challenge to the model. B-ORG and I-ORG as seen in confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Get confusion matrix for validation set\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cmatrix = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cmatrix, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], tags.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequences with high loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            # Skip padding tokens and special tokens\n",
    "            if i not in (0, len(row[\"attention_mask\"])):   \n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "            \n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels,\n",
    "            \"preds\": preds, \"losses\": losses}).T\n",
    "        \n",
    "        yield df_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.56</td>\n",
       "      <td>9.60</td>\n",
       "      <td>8.45</td>\n",
       "      <td>5.35</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.59</td>\n",
       "      <td>7.40</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>7.19</td>\n",
       "      <td>8.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9    \n",
       "tokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''  \\\n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  I-ORG     O     O      O      O  B-ORG      O   \n",
       "losses  0.00  0.00   4.58  -0.00  0.00  0.00  10.56   9.60   8.45   5.35   \n",
       "\n",
       "           10     11     12     13     14     15     16     17     18  \n",
       "tokens     ▁'     ri    ▁''     ▁'      k    ▁''     ▁'    ala   </s>  \n",
       "labels  I-LOC    IGN  I-LOC  I-LOC    IGN  I-LOC  I-LOC    IGN    IGN  \n",
       "preds       O      O      O      O      O      O      O      O      O  \n",
       "losses   6.87  -0.00   6.59   7.40  -0.00   7.19   8.01  -0.00  -0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>8.34</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>6.26</td>\n",
       "      <td>8.08</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6.22</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>7.27</td>\n",
       "      <td>9.11</td>\n",
       "      <td>6.92</td>\n",
       "      <td>5.72</td>\n",
       "      <td>6.46</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5         6      7      8    \n",
       "tokens    ▁''      8      .  ▁Juli    ▁''     ▁:  ▁Protest   camp   ▁auf  \\\n",
       "labels  B-ORG    IGN    IGN  I-ORG  I-ORG  I-ORG     I-ORG    IGN  I-ORG   \n",
       "preds       O      O      O      O      O      O         O      O      O   \n",
       "losses   8.34  -0.00  -0.00   6.26   8.08   9.09      6.22  -0.00   7.27   \n",
       "\n",
       "           9         10     11          12     13      14     15     16     17  \n",
       "tokens   ▁dem  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de   </s>  \n",
       "labels  I-ORG     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN    IGN  \n",
       "preds       O         O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG  I-ORG  \n",
       "losses   9.11      6.92   5.72        6.46  -0.00   -0.00   0.02  -0.00  -0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>5.97</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.98</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>5.74</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>5.66</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.43</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6    \n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil  \\\n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     5.97      5.27    5.98        -0.00      5.74  -0.00     5.66   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses    -0.00      5.36   5.89   5.90      5.64      5.51       5.43  -0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Lingual Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    # Move trainer to cpu\n",
    "    trainer.model.to(\"cpu\")\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cec18b31694c24a55e60b433292cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.862\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9    \n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en  \\\n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ▁Cali    for    nie  </s>  \n",
       "Tags    B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b226594eea4041bffb0e1d657e364c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7f5001fbd24a38b879b1a9bc36f956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14622d83f58c49d491af0779f7543e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.692\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f9f6a74c014862904415078a6398e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9979e5fedd147ab88528c8f3159f777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e97570ff9064f9387921b9e55d58964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.682\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2652da0e135041f88ff4db9ce9c8254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2836789288e344e28506baab78a35543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5efbbd82064111ba3988836be966f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.585\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Does Zero-Shot Transfer Make Sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    \n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "    # Initialize model from scratch\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.model.to(device)\n",
    "    trainer.train()\n",
    "\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    \n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"num_samples\": [len(train_ds)], \n",
    "            \"f1_score\": [f1_score]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c1fea5b8dd419b9c9f18e60defb232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015521968f24ccfa971d943b3436257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb171b10d204c9e94a68c532302569b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "panx_fr_encoded = encode_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args\u001b[39m.\u001b[39mpush_to_hub \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Fine-tuning on French with 250 data points underperforms the\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# zero-shot transfer from German by a large margin\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m metrics_df \u001b[39m=\u001b[39m train_on_subset(panx_fr_encoded, \u001b[39m250\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m metrics_df\n",
      "Cell \u001b[0;32mIn[131], line 9\u001b[0m, in \u001b[0;36mtrain_on_subset\u001b[0;34m(dataset, num_samples)\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args\u001b[39m.\u001b[39mlogging_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_ds) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m      8\u001b[0m \u001b[39m# Initialize model from scratch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model_init\u001b[39m=\u001b[39;49mmodel_init, args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m     10\u001b[0m                     data_collator\u001b[39m=\u001b[39;49mdata_collator, compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[1;32m     11\u001b[0m                     train_dataset\u001b[39m=\u001b[39;49mtrain_ds, eval_dataset\u001b[39m=\u001b[39;49mvalid_ds, tokenizer\u001b[39m=\u001b[39;49mxlmr_tokenizer, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     12\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     14\u001b[0m f1_score \u001b[39m=\u001b[39m get_f1_score(trainer, test_ds)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "training_args.push_to_hub = False\n",
    "# Fine-tuning on French with 250 data points underperforms the\n",
    "# zero-shot transfer from German by a large margin\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(train_on_subset(panx_fr_encoded, num_samples), \n",
    "                                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 750 training examples, fine-tuning on French reaches a similar level of performance as fine-tuning on German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axhline(f1_scores[\"de\"][\"fr\"], ls=\"--\", color=\"r\")\n",
    "metrics_df.set_index(\"num_samples\").plot(ax=ax)\n",
    "\n",
    "plt.legend([\"Zero-shot from de\", \"Fine-tuned on fr\"], loc=\"lower right\")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Language Fine-Tuning at Once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate German and French dataset to check for performance improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "                                    [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    \n",
    "    return multi_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'panx_de_fr_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args\u001b[39m.\u001b[39mlogging_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(panx_de_fr_encoded[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m      2\u001b[0m training_args\u001b[39m.\u001b[39mpush_to_hub \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m training_args\u001b[39m.\u001b[39moutput_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxlm-roberta-base-finetuned-panx-de-fr\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'panx_de_fr_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "                    eval_dataset=panx_de_fr_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "# trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all langugaes dataset to check for performance improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = [panx_de_encoded]\n",
    "\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-finetuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-finetuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "                    eval_dataset=corpora_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get F1-score for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, lang in enumerate(langs):\n",
    "    f1_scores[\"all\"][lang] = get_f1_score(trainer, corpora[idx][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = {\n",
    "    \"de\": f1_scores[\"de\"],\n",
    "    \"each\": {lang: f1_scores[lang][lang] for lang in langs},\n",
    "    \"all\": f1_scores[\"all\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_df = pd.DataFrame(scores_data).T.round(4)\n",
    "f1_scores_df.rename_axis(index=\"Fine-tune on\", columns=\"Evaluated on\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for MAD-X adaption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
